import streamlit as st
import joblib
import pandas as pd
import requests
import json
import os
import random
import time

st.set_page_config(page_title="DiskML Model", layout="wide")

if "last_placeholder_update" not in st.session_state:
    st.session_state.last_placeholder_update = 0
if "current_placeholder" not in st.session_state:
    st.session_state.current_placeholder = "Ready to help..."

placeholder_vprasanja = [
    "Processing your request...",
    "Understanding context...",
    "Thinking longer for better answer...",
    "Formulating a response...",
    "Analyzing logic...",
    "Connecting the dots..."
]

trenutni_cas = time.time()
if trenutni_cas - st.session_state.last_placeholder_update > 10:
    st.session_state.current_placeholder = random.choice(placeholder_vprasanja)
    st.session_state.last_placeholder_update = trenutni_cas


@st.cache_resource
def load_resources():
    try:
        importance = pd.read_csv('feature_importance.csv')
        model = joblib.load('disk_model.pkl')
        return importance, model
    except Exception as e:
        st.error(f"Napaka pri nalaganju datotek: {e}")
        return None, None


importance_df, model_rf = load_resources()

st.sidebar.title("ğŸ“Š Podatki o modelu")

if st.sidebar.button("ğŸ—‘ï¸ PoÄisti zgodovino pogovora"):
    st.session_state.messages = []
    st.rerun()

if importance_df is not None:
    st.sidebar.write("### Pomembnost znaÄilnic (Top 10)")
    st.sidebar.dataframe(importance_df.head(10), hide_index=True)

st.sidebar.markdown("---")
st.sidebar.write("**NatanÄnost:** 90.15%")
st.sidebar.write("**Recall (pravilno napovedane odpovedi):** 86%")
st.sidebar.info("Model temelji na Random Forest algoritmu in je bil nauÄen na 8.828 uravnoteÅ¾enih instancah.")

st.title("ğŸ¤– DiskML AI Sogovornik")
st.markdown("""
Ta vmesnik ti omogoÄa pogovor z AI modelom o logiki modela za napovedovanje odpovedi diskov.
VpraÅ¡aÅ¡ ga lahko karkoli o modelu, strojnem uÄenju ali o vplivih na odpoved diska nasploh.
Zaradi lightweight llama modela, ima model v kontekstu zadnjih 20 vpraÅ¡Äanj uporabnika.
""")

if "messages" not in st.session_state:
    st.session_state.messages = []

# pretekla sporocila
for message in st.session_state.messages:
    # Ohranimo ikone pri izrisu zgodovine
    avatar = "ğŸ¤–" if message["role"] == "assistant" else None
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

if prompt := st.chat_input("VpraÅ¡aj me karkoli..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    context_data = importance_df.head(15).to_string(index=False) if importance_df is not None else ""

    system_prompt = f"""
        Si visoko strokovni svetovalec za strojno uÄenje in zanesljivost shranjevanja podatkov. 
        Tvoja naloga je pomagati uporabniku interpretirati rezultate naprednega sistema za napovedovanje odpovedi diskov, 
        ki temelji na algoritmih gruÄenja, klasifikacije in regresije.

        TEHNIÄŒNE SPECIFIKACIJE SISTEMA, KI JIH PREDSTAVLJAÅ  UPORABNIKU:
        - Skupna natanÄnost napovedi: 90.15%
        - Recall (sposobnost zaznave dejanskih odpovedi): 86%
        - KljuÄni SMART parametri, na katerih temelji odloÄanje sistema:
        {context_data}

        NAVODILA ZA KOMUNIKACIJO:
        1. Ne obravnavaj avtorja modela, temveÄ se posveti izkljuÄno uporabniku, ki trenutno uporablja chat.
        2. Odgovori morajo biti objektivni in strokovni. Namesto "tvoj model" uporabi "sistem za analizo" ali "uporabljeni model".
        3. ÄŒe uporabnik vpraÅ¡a o pomembnosti parametrov, mu razloÅ¾i vlogo zgoraj navedenih SMART atributov v kontekstu zanesljivosti.
        4. Poleg specifikacij sistema si pripravljen odgovarjati tudi na sploÅ¡na vpraÅ¡anja o vzdrÅ¾evanju diskov, delovanju SMART tehnologije, vplivih okolja na strojno opremo ter teoriji strojnega uÄenja.
        5. Govori razumljivo, a ohrani avtoriteto strokovnjaka. Uporabniku nudiÅ¡ vpogled v to, kako tehnologija varuje njegove podatke.
        """

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        message_placeholder = st.empty()

        # TAKOJ izpiÅ¡emo nakljuÄen procesni stavek, da uporabnik vidi aktivnost
        thinking_text = random.choice(placeholder_vprasanja)
        message_placeholder.markdown(f"*{thinking_text}*")

        full_response = ""

        try:
            url = "http://ollama:11434/api/generate"

            # sliding windows, kontekst sledi samo zadnjim 20 vprasanjem..
            MAX_HISTORY = 20
            recent_messages = st.session_state.messages[-MAX_HISTORY:]

            history_context = ""
            for msg in recent_messages[:-1]:  # vzamemo vse razen Äisto zadnjega prompta
                role = "Uporabnik" if msg["role"] == "user" else "AI"
                history_context += f"{role}: {msg['content']}\n"

            payload = {
                "model": "llama3",
                "prompt": f"{system_prompt}\n\nZgodovina pogovora:\n{history_context}\nUporabnik spraÅ¡uje: {prompt}",
                "stream": False
            }

            response = requests.post(url, json=payload, timeout=500)

            if response.status_code == 200:
                full_response = response.json().get('response', 'AI ni vrnil odgovora.')
            else:
                full_response = f"Napaka: Ollama je vrnila status {response.status_code}."

        except requests.exceptions.ConnectionError:
            full_response = "Napaka: Ne morem se povezati z Ollama storitvijo. Preveri, Äe container 'ollama_service' teÄe."
        except Exception as e:
            full_response = f"PriÅ¡lo je do napake: {e}"

        # Dejanski odgovor prepiÅ¡e procesni stavek
        message_placeholder.markdown(full_response)

    # dodajanje odgovorov
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # refresh
    st.session_state.last_placeholder_update = 0
